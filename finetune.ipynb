{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/hyintell/BLOOM-fine-tuning.git\n",
        "%cd BLOOM-fine-tuning\n",
        "! pip install -r requirements.txt "
      ],
      "metadata": {
        "id": "eDg5XB5XSOvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "Rs-fO-45SZ7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import BloomTokenizerFast, BloomForCausalLM, TrainingArguments\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from utils import ModifiedTrainer, tokenise_data, data_collator"
      ],
      "metadata": {
        "id": "Y1K0wM03SUC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Main"
      ],
      "metadata": {
        "id": "v0pkIZelS8V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "rYJZvgDGS78C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bloom-1b7\"\n",
        "model = BloomForCausalLM.from_pretrained(f\"bigscience/{model_name}\")\n",
        "tokeniser = BloomTokenizerFast.from_pretrained(f\"bigscience/{model_name}\", add_prefix_space=True)"
      ],
      "metadata": {
        "id": "XSVC2chxSTBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('tatsu-lab/alpaca')\n",
        "input_ids = tokenise_data(dataset, tokeniser)"
      ],
      "metadata": {
        "id": "nqfIQ_EQTM3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model.is_parallelizable = True\n",
        "model.model_parallel = True\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"output\",\n",
        "    fp16=False,\n",
        "    gradient_accumulation_steps= 1,\n",
        "    per_device_train_batch_size = 2,\n",
        "    learning_rate = 2e-5,\n",
        "    num_train_epochs=2,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = ModifiedTrainer(\n",
        "    model=model,\n",
        "    train_dataset=input_ids,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "j02eVqAoTWsU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}